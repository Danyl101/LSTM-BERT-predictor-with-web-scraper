							MACHINE LEARNING DEBUG REPORT



Tags:[Mismatch,Loss,Variance]
__________________________________________________________________________
Error

return self.relu(x + res)
                     ~~^~~~~
RuntimeError: The size of tensor a (64) must match the size of tensor b (60) at non-singleton dimension 2

Reason and Solution 

 The conv layer(x) reduces the time steps presents which is created by dilation and kernel size , this is usually offset by padding which is this case was not

 enough , so we did a slight code snippet to reduce the time steps either from conv layer(x) or residual layer(res) depending on which was bigger

if x.size(2) > res.size(2):
    x = x[:, :, :res.size(2)]			x[B:C:T] where B =Batch Size  	
elif x.size(2) < res.size(2):  				       C= Channels
    res = res[:, :, :x.size(2)]                                T=Time Steps

						here x[B:C:T(begin):T(end)] basically sliced off the end portion of T 

_______________________________________________________________________________

Note [Loss]

Low Training Loss and High Validation Loss indicates that the model is either overfitting , or has poor generalization , in this case it was due to large difference between even standardised values present in training set , validation set , test set , which caused machine to not be able to predict validation test properly, this was mitigated by log transformation 

___________________________________________________________________________________

Note[Loss]

High Training Loss and Low Validation Loss indicates that the model has data leakage as in data is leaked from training to validation and test sets , occurs when you use same scaler and fit_transform multiple times with same scaler

___________________________________________________________________________________

Note [Loss,Variance]

If the variance between train , test and val values is what might be causing issues , then increasing dilation , kernel size for training in train dataset might make it help understand the patterns more since it can look at further and contextualise in a larger region

___________________________________________________________________________________

Error 

RuntimeError: expected padding to be a single integer value or a list of 1 values to match the convolution dimensions, but got padding=[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]

for i, out_channels in enumerate(num_channels):
            #Dilation increases the time steps checked by convoluion
            dilation = [1,2,3,4]
            layers.append(TCNBlock(in_channels, out_channels, kernel_size, dilation))
            in_channels = out_channels

self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,
                               padding=(kernel_size - 1) * dilation,
                               dilation=dilation)

Reason and Solution

Since padding is generated by multiplying kernel sizes with dilation values , here since dilation is an array , the padding multiplied the array which caused the padding to contain multiple arrays instead of a single digit 

____________________________________________________________________________________________


            